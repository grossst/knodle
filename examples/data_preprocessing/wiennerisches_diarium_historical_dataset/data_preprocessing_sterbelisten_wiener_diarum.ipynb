{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wiener Diarum Sterbelisten: Data Preprocessing for Sequence Labeling\n",
    "-----------------------------------------------------------------------------------------------\n",
    "\n",
    "### Data\n",
    "\n",
    "The Wiener Zeitung is the oldest running newspaper in the world. It started in 1703 as Wiener Diarum and changed in 1780 to Wiener Zeitung. Through its central role in the Habsburg monarchy it distributed knowledge across all disciplines throughout Europe. This also helped to put Vienna into a more prominent position.\n",
    "\n",
    "\n",
    "The Austrian Centre for Digital Humanities and Cultural Heritage of the Austrian Academy of Sciences (ACDH-CH) started a project with the goal of digitalising and providing this historically important data. The digitised newspapers as well as current developements can be found here: \n",
    "https://digitarium.acdh.oeaw.ac.at/willkommen/\n",
    "\n",
    "https://www.oeaw.ac.at/ihb/forschungsbereiche/kunstgeschichte/forschung/habsburgische-repraesentation/das-wiennerische-diarium\n",
    "\n",
    "\n",
    "This valuable resource is useful for multiple disciplines as it holds historical data on science, politics, cultural and other sections. It is interesting for linguistic research as the normalisation of german orthography only started at the end of the 18th century and was only fully set in force in the late 19th century.  \n",
    "\n",
    "For this task there is data prepared by the research group of the ACDH-CH. The digitalised Wiener Zeitung is partially available as TEI XML as well as an extracted HTML on Github. This data set contains only a few newspapers per year starting from 1706.\n",
    "\n",
    "The link to the Github Repository of the ACDH-CH research group shows their current work process as well as the original data used for this tutorial: https://github.com/acdh-oeaw/sterbelisten\n",
    "\n",
    "\n",
    "\n",
    "### Task\n",
    "\n",
    "In this tutorial we want to prepare the data provided by the research group of the ACDH-CH in order to apply sequence labeling to it and fit the data into the Knodle framework.\n",
    "\n",
    "Our goal is to automatically find the place names in the obituaries. These lists are in every newspaper issue and contain several notes about the death of people. Usually they contain the name, age, reason and place of death. By filtering out the place names automatically, one can extract historical knowledge about the city of Vienna and its developement as well as orthographical changes and therewith historical linguistical knowledge.\n",
    "\n",
    "For this sequence labelling task we need to build the data in a way that is suitable for a weakly supervised machine learning approach. We will need to read the .html file and clean all the additional characters as illustrated later on in this tutorial. We will also tokenise the words given and translate the provided \\<mark> tags into a matrix format that provides the location of the toponym within the sentence. Our rules are the tagged place names, which are a result of the work made by the team of the ACDH-CH. We want to train a model that can detect place names by using the data we are provided with by the research group of the ACDH-CH. As this data is extremly difficult to organise due to the big spelling variation, it is our goal to try a machine learning approach rather than a rule-based approach.\n",
    "\n",
    "\n",
    "##### What we have: provided by the research group of the ACDH-CH\n",
    "The approach of the research group of the ACDH-CH is a rule-based approach on finding place names.  By creating patterns with which they would identify place names and compare them to historical dictionaries, they gather place names in order to link them to other sources. \n",
    "\n",
    "For example regular expressions containing prepositons and other words that would occur in those obituaries (Sterbelisten) are used as patterns. The matched words are then extracted and sent to DTA-CAB (https://www.deutschestextarchiv.de/doku/software); another online tool that compares historically varying spelling by comparing it to historical dictionaries and using sound-distance measures like the Levenshtein distance measure. \n",
    "\n",
    "\n",
    "- A .html file that has \\<mark> on most toponyms but sometimes on persons and other names too.\n",
    "\n",
    "- A .xml file containing the sterbelisten.\n",
    "\n",
    "- A .csv files with Toponyms extracted from Wien Geschichte Wiki.\n",
    "\n",
    "- A .txt file containing a list with sucessfully extracted toponyms, which are already normalised into contemporary orthography by comparing the results with the Wien Geschichte Wiki(https://www.geschichtewiki.wien.gv.at/Wien_Geschichte_Wiki).\n",
    "\n",
    "- Some notebooks and other files.\n",
    "\n",
    "As the ACDH-CH research group is actively working on their project, the Github repository is constantly changing and developing. For our Tutorial we will only use the .html file as it contains the marked place names we need to build our training data.\n",
    "\n",
    "##### What we want: Knodle-compatible input\n",
    "###### A training and test set for our sequence labeling task containing three matrices:\n",
    "- T Matrix containing the classes and the rules (panda data frame with the dimensions 2xnumber of place names).\n",
    "- Z Matrices one for each sentence each containing the words in the sentence and all our rules (=place names)(np.matrix, sparse).\n",
    "- X Matrix containing the samples (pandas data frame).\n",
    "\n",
    "\n",
    "##### Pipeline\n",
    "\n",
    "**1. Read in the html file**\n",
    "\n",
    "- Strip of tags and clean the text with regular expressions.\n",
    "\n",
    "- Create a list with each sentence as a sample.\n",
    "\n",
    "We decided to keep the abbreviations as the expansion would already involve normalisation and we want to try to work with the 'raw' data.\n",
    "\n",
    "\n",
    "**2. Read in already extracted placenames**\n",
    "- Extract all \\<mark> words from the .html file provided by the ACDH-CH research group and assign an ID.\n",
    "- Loop through all samples and create lists containing either None if the word is not a place name or the ID of the place name if the word is part of a place name.\n",
    "\n",
    "\n",
    "**3. Building training data**\n",
    "\n",
    "**X Matrix:**\n",
    "pandas data frame or list with all  cleaned sentences.\n",
    "\n",
    "**T Matrix**\n",
    "np.sparse matrix, one column 0, one column 1, rows are place names.\n",
    "\n",
    "**Z Matrices**\n",
    "numpy.narray\n",
    "columns= keywords \n",
    "rows = words in sentence\n",
    "\n",
    "\n",
    "**5. Building test data** \n",
    "\n",
    "manually checked! \n",
    "There is the 'timemachine_evaluatuin_v1_edited_corrected.jsonl which should contain manually corrected place names but it is not usable for our purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Please check requirements are in the requirements.txt \n",
    "\n",
    "The code in this tutorial is also available as a data_preprocessing_wiener_diarum_toponym.py.\n",
    "\n",
    "This folder contains: \n",
    "- data_preprocessing_sterbelisten_wiener_diarum.ipn\n",
    "- data_preprocessing_wiener_diarum_toponym.py\n",
    "- requirements.ipynb\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "from tqdm import tqdm\n",
    "from joblib import dump\n",
    "from minio import Minio\n",
    "client = Minio(\"knodle.cc\", secure=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../../data_from_minio/wiener_diarum_toponyms'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the path to the folder where the data will be stored\n",
    "data_path = \"../../../data_from_minio/wiener_diarum_toponyms\"\n",
    "os.makedirs(data_path, exist_ok=True)\n",
    "os.path.join(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 1/1 [00:01<00:00,  1.19s/it]\n"
     ]
    }
   ],
   "source": [
    "files = [\"annotations_3-21_v4.html\"]\n",
    "\n",
    "\n",
    "for file in tqdm(files):\n",
    "    client.fget_object(\n",
    "        bucket_name=\"knodle\",\n",
    "        object_name=os.path.join(\"datasets/wiener_diarum_toponyms/\",file),\n",
    "        file_path=os.path.join(data_path, file[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read in .html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load html file\n",
    "\n",
    "with open(os.path.join(data_path, file[-1]), 'r', encoding = \"utf-8\" ) as f:\n",
    "    sterbelisten_html = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The .html file contains many tags and information that is redundant and not needed for our nlp task, one example : \n",
    "\n",
    "``` \n",
    "<h2>Lista aller Verstorbenen in und vor der Stadt .  | Den 3 . Februarii 1706 .  | Den 4 . dito .  | Den 5 . Dito . </h2><h3>/db/apps/edoc/data/170x/1706/02/1706-02-03.xml | i51</h3><br/>\\r\\n    <p>Dem Peter# Frost / einem Cammer im <mark>Greiseckeris  Hauß</mark> im <mark>Diener  Gäßl</mark> / sein Kind Frantz / alt 6 . viertl Jahr .####################### </p>\\r\\n<hr/>\\r\\n<h2>Lista aller Verstorbenen in und vor der Stadt .  | Den 3 . Februarii 1706 .  | Den 4 . dito .  | Den 5 . Dito . </h2><h3>/db/apps/edoc/data/170x/1706/02/1706-02-03.xml | i52</h3><br/>\\r\\n    <p>Der Maria# Nauitschanin / einer Burgerl . Wittib im <mark>Primis  Hauß</mark> auf der <mark>Wen=delstadt</mark> / ihr Kind Carl / alt 5 . Jahr .########## </p>\\r\\n<hr/>\\r\\n\n",
    "\n",
    "```\n",
    "We want to clean this document in order to obtain the actual sentence, like here: \n",
    "\n",
    "```\n",
    "\\ Dem Peter Frost / einem Cammer im <mark>Greiseckeris  Hauß</mark> im <mark>Diener  Gäßl</mark> / sein Kind Frantz / alt 6 viertl Jahr\n",
    "```\n",
    "Note that we don't want to lose the \\<mark> and \\<\\mark> tags as we will need them later to collect all place names. The Wiener Diarum also contains a lot of / partially as markers to signal that there is a line break in the sentence or a noun or verb that is seperated into two words. \n",
    "\n",
    "We clean the expression using regex as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the text first from both html tags and xml tags and then in a second step clean the intro and replace with /n\n",
    "\n",
    "# get rid of the title of the issue and the xml tags by just replacing the whole intro with \"\"\n",
    "sterbelisten_strip_html_1 = re.sub(r\"<h2>.*</h2><h3>.*xml \\|.*\\d+</h3><br/>\",\"\",sterbelisten_html)\n",
    "\n",
    "# now working on all the tags around the sentences and weird characters within the words\n",
    "sterbelisten_strip_html1 = re.sub(r\"<hr/>|<p>|</p>|#+|=| =|<html>|</html>|\\r|\\b \\.|\\b# \\.|(|)\",\"\",sterbelisten_strip_html_1)#<mark>|</mark>\n",
    "\n",
    "sterbelisten_strip_html2 = re.sub(r\"    \\b\",\"\",sterbelisten_strip_html1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13163"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an empty list and split the text at line break, creating an element for each sentence\n",
    "\n",
    "sterbeliste = []\n",
    "sterbeliste = sterbelisten_strip_html2.split(\"\\n\\n\\n\")\n",
    "len(sterbeliste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Create labeled sentences and a dictionary of place names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open questions:\n",
    "\n",
    "This code works on the assumption that both \\<mark> and \\<\\mark> tags are present.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of <mark> tags: 14870\n",
      "Number of </mark> tags: 11646\n",
      "Number of unclosed tags: 3224\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of <mark> tags: {len(re.findall('<mark>',sterbelisten_html))}\")\n",
    "print(f\"Number of </mark> tags: {len(re.findall('</mark>',sterbelisten_html))}\")\n",
    "print(f\"Number of unclosed tags: {len(re.findall('<mark>',sterbelisten_html))-len(re.findall('</mark>',sterbelisten_html))}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, there are 14870 \\<mark> and 11646 \\<\\mark> tags, what can be explained by some errors in preprocessing. \n",
    "We solve this by exluding the 3224 items and their samples from our list, or check them manually and use a cleaned html file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_location_id(curr_loc: List, all_loc: Dict) -> Tuple[int,Dict]:\n",
    "    '''\n",
    "    Descr: This function loops through the list of place names, \n",
    "    if it doesn't find a given place name it adds the place name to the list\n",
    "    and returns the new list \n",
    "    \n",
    "    Args: the list or single word that is part of a place name\n",
    "    Returns: list of place names \n",
    "    '''\n",
    "    for word in curr_loc:\n",
    "        if word not in all_loc:\n",
    "            all_loc[word]= len(all_loc)\n",
    "        return all_loc[word]\n",
    "\n",
    "    \n",
    "    \n",
    "def preprocess_sentence(sentence):\n",
    "    '''\n",
    "    This function replaces the <mark> tag with <start> and the </mark> tag with <end> in order\n",
    "    to clean the remaining / out of the senctenses. It then splits the sentence into seperate words\n",
    "    and returns a list with all words in the senctense.\n",
    "    \n",
    "    Args: \n",
    "        \"sentece\" is the sentence as a string containing <mark> and </mark> and several \"/\".\n",
    "    Returns: \n",
    "        A list with all words in the sentence split by \" \" cleaned from \"/\" and \n",
    "        containing <start> and <end> tag instead of <mark>\n",
    "    '''\n",
    "    sentence = re.sub(r\"<mark>\",\"<start> \",sentence)\n",
    "    sentence = re.sub(r\"</mark>\",\" <end>\",sentence)\n",
    "    sentence = re.sub(r\"\\(|\\)|/\",\"\",sentence)\n",
    "    sentence = sentence.split(\" \")\n",
    "    sentence = list(filter(None,sentence))\n",
    "    return sentence\n",
    "\n",
    "\n",
    "def create_labels(sterbeliste: List):\n",
    "    '''\n",
    "    Loops through the sentences and creates a list with Labels for each word in a sentence.\n",
    "    It also creates a dictionary with an ID for each place name\n",
    "    and collects all cleaned and preprocessed sentences as a list of lists.\n",
    "    \n",
    "    Args: \n",
    "        sentence= a sentence as a string\n",
    "        current_loc= a list with all words that are within one place name tag.\n",
    "        labels=  list with labels for each word, None if it is not a place name and the\n",
    "        ID of the occuring place name if a word belongs to a place name.\n",
    "    Return:\n",
    "        samples = a list with all label lists for all sentences.\n",
    "        clean_sterbeliste= a list each sentence as a list of words.\n",
    "        all_loc= a dictionary with all place names and its ID number.\n",
    "    \n",
    "    '''\n",
    "    # we create a dictionary locations that contains the place name as a key and the ID as a value\n",
    "    all_loc={}\n",
    "\n",
    "    # we collect our tagged sentences in samples, these contain None for each word that is no place name and the corresponding ID to each word that is part of a place name \n",
    "    samples = []\n",
    "\n",
    "    # we collect a list with each sentence that is a list containing each word as its elements\n",
    "    clean_sterbeliste=[]\n",
    "\n",
    "\n",
    "    for sentence in sterbeliste:\n",
    "        if re.search(r\"/mark\", sentence) is None:\n",
    "            continue\n",
    "        labels=[]\n",
    "        sentence = preprocess_sentence(sentence)\n",
    "        if_loc= False\n",
    "        for word in sentence:\n",
    "            if word=='<start>':\n",
    "                if_loc= True\n",
    "                curr_loc = []\n",
    "            elif word=='<end>':\n",
    "                labels +=[get_location_id(curr_loc, all_loc)] * len(curr_loc)\n",
    "                if_loc= False\n",
    "            else:\n",
    "                if if_loc:\n",
    "                    curr_loc.append(word)\n",
    "                else:\n",
    "                    labels.append(None)\n",
    "        samples.append(labels)\n",
    "        sentence= [word for word in sentence if word !=\"<start>\" if word!=\"<end>\"]\n",
    "        clean_sterbeliste.append(sentence)\n",
    "    return samples, clean_sterbeliste, all_loc\n",
    "        \n",
    "        \n",
    "samples, clean_sterbeliste, all_loc = create_labels(sterbeliste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample_tagging:[None, None, None, None, None, None, 0, 0, None, 1, 1, None, None, None, None, None, None, None]\n",
      "Cleaned Sentence: ['\\nDem', 'Peter', 'Frost', 'einem', 'Cammer', 'im', 'Greiseckeris', 'Hauß', 'im', 'Diener', 'Gäßl', 'sein', 'Kind', 'Frantz', 'alt', '6', 'viertl', 'Jahr']\n",
      "=======================================\n",
      "Number of place names: 2911\n",
      "Number of sample sentences: 7412\n",
      "=======================================\n"
     ]
    }
   ],
   "source": [
    "print(f\"Sample_tagging:{samples[0]}\")\n",
    "print(f\"Cleaned Sentence: {clean_sterbeliste[0]}\")\n",
    "print(f\"=======================================\")\n",
    "print(f\"Number of place names: {len(all_loc)}\")\n",
    "print(f\"Number of sample sentences: {len(clean_sterbeliste)}\")\n",
    "print(f\"=======================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3.Building training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>[Joseph, Gaßrann, Wais, in, dem, Englischen, H...</td>\n",
       "      <td>[None, None, None, None, None, 123, 123, None,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>[Christina, Zaplerin, lediges, Mensch, bey, de...</td>\n",
       "      <td>[None, None, None, None, None, None, 8, 8, Non...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>[Dem, Herrn, Frantz, v, ,, Königl, Spanischer,...</td>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>[Herr, Wolf, Joseph, Hofmandl, v, ,, StadtHaup...</td>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>[Dem, Herrn, Johann, Fridmann, Kaiserl, ,, s, ...</td>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7407</th>\n",
       "      <td>[Philipp, Spitzer, ,, led, alt, 18, J, im, Jud...</td>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7408</th>\n",
       "      <td>[Hr, Bernard, Abbe, v, Berzoni, ,, d, h, r, N,...</td>\n",
       "      <td>[None, None, None, 131, 131, None, None, None,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7409</th>\n",
       "      <td>[Der, Fr, ., Cath, Resch, ,, bg, Kaffeehausinh...</td>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7410</th>\n",
       "      <td>[Hr, Daniel, Freyhr, Rottern, v, und, zu, Kost...</td>\n",
       "      <td>[None, None, None, None, None, None, None, 291...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7411</th>\n",
       "      <td>[Anna, Spitzer, ,, led, alt, 22, J, im, Judens...</td>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7312 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 sample  \\\n",
       "100   [Joseph, Gaßrann, Wais, in, dem, Englischen, H...   \n",
       "101   [Christina, Zaplerin, lediges, Mensch, bey, de...   \n",
       "102   [Dem, Herrn, Frantz, v, ,, Königl, Spanischer,...   \n",
       "103   [Herr, Wolf, Joseph, Hofmandl, v, ,, StadtHaup...   \n",
       "104   [Dem, Herrn, Johann, Fridmann, Kaiserl, ,, s, ...   \n",
       "...                                                 ...   \n",
       "7407  [Philipp, Spitzer, ,, led, alt, 18, J, im, Jud...   \n",
       "7408  [Hr, Bernard, Abbe, v, Berzoni, ,, d, h, r, N,...   \n",
       "7409  [Der, Fr, ., Cath, Resch, ,, bg, Kaffeehausinh...   \n",
       "7410  [Hr, Daniel, Freyhr, Rottern, v, und, zu, Kost...   \n",
       "7411  [Anna, Spitzer, ,, led, alt, 22, J, im, Judens...   \n",
       "\n",
       "                                                 labels  \n",
       "100   [None, None, None, None, None, 123, 123, None,...  \n",
       "101   [None, None, None, None, None, None, 8, 8, Non...  \n",
       "102   [None, None, None, None, None, None, None, Non...  \n",
       "103   [None, None, None, None, None, None, None, Non...  \n",
       "104   [None, None, None, None, None, None, None, Non...  \n",
       "...                                                 ...  \n",
       "7407  [None, None, None, None, None, None, None, Non...  \n",
       "7408  [None, None, None, 131, 131, None, None, None,...  \n",
       "7409  [None, None, None, None, None, None, None, Non...  \n",
       "7410  [None, None, None, None, None, None, None, 291...  \n",
       "7411  [None, None, None, None, None, None, None, Non...  \n",
       "\n",
       "[7312 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# saving the training data, leaving 100 samples as test data\n",
    "\n",
    "d = {\"sample\": clean_sterbeliste, \"labels\":samples}\n",
    "\n",
    "df = pd.DataFrame(d)\n",
    "\n",
    "df_train = df[100:]\n",
    "df_train.to_csv(os.path.join(data_path, 'df_train.csv'))\n",
    "\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7412, 66)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nDem</td>\n",
       "      <td>Peter</td>\n",
       "      <td>Frost</td>\n",
       "      <td>einem</td>\n",
       "      <td>Cammer</td>\n",
       "      <td>im</td>\n",
       "      <td>Greiseckeris</td>\n",
       "      <td>Hauß</td>\n",
       "      <td>im</td>\n",
       "      <td>Diener</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Der</td>\n",
       "      <td>Maria</td>\n",
       "      <td>Nauitschanin</td>\n",
       "      <td>einer</td>\n",
       "      <td>Burgerl</td>\n",
       "      <td>Wittib</td>\n",
       "      <td>im</td>\n",
       "      <td>Primis</td>\n",
       "      <td>Hauß</td>\n",
       "      <td>auf</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Christina</td>\n",
       "      <td>Kochin</td>\n",
       "      <td>ein</td>\n",
       "      <td>Wittib</td>\n",
       "      <td>im</td>\n",
       "      <td>Barbieris</td>\n",
       "      <td>Hauß</td>\n",
       "      <td>auf</td>\n",
       "      <td>der</td>\n",
       "      <td>Laimgrueben</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gottlieb</td>\n",
       "      <td>Rabel</td>\n",
       "      <td>ein</td>\n",
       "      <td>gewester</td>\n",
       "      <td>Haußmeister</td>\n",
       "      <td>beyn</td>\n",
       "      <td>3</td>\n",
       "      <td>Mohren</td>\n",
       "      <td>in</td>\n",
       "      <td>der</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dominica</td>\n",
       "      <td>Stephanebrin</td>\n",
       "      <td>ein</td>\n",
       "      <td>lediges</td>\n",
       "      <td>Mensch</td>\n",
       "      <td>beym</td>\n",
       "      <td>weissen</td>\n",
       "      <td>Ochsen</td>\n",
       "      <td>bey</td>\n",
       "      <td>St</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7407</th>\n",
       "      <td>Philipp</td>\n",
       "      <td>Spitzer</td>\n",
       "      <td>,</td>\n",
       "      <td>led</td>\n",
       "      <td>alt</td>\n",
       "      <td>18</td>\n",
       "      <td>J</td>\n",
       "      <td>im</td>\n",
       "      <td>Judensp</td>\n",
       "      <td>in</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7408</th>\n",
       "      <td>Hr</td>\n",
       "      <td>Bernard</td>\n",
       "      <td>Abbe</td>\n",
       "      <td>v</td>\n",
       "      <td>Berzoni</td>\n",
       "      <td>,</td>\n",
       "      <td>d</td>\n",
       "      <td>h</td>\n",
       "      <td>r</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7409</th>\n",
       "      <td>Der</td>\n",
       "      <td>Fr</td>\n",
       "      <td>.</td>\n",
       "      <td>Cath</td>\n",
       "      <td>Resch</td>\n",
       "      <td>,</td>\n",
       "      <td>bg</td>\n",
       "      <td>Kaffeehausinhab</td>\n",
       "      <td>Wit</td>\n",
       "      <td>i</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7410</th>\n",
       "      <td>Hr</td>\n",
       "      <td>Daniel</td>\n",
       "      <td>Freyhr</td>\n",
       "      <td>Rottern</td>\n",
       "      <td>v</td>\n",
       "      <td>und</td>\n",
       "      <td>zu</td>\n",
       "      <td>Kostenthal</td>\n",
       "      <td>,</td>\n",
       "      <td>Weltpriest</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7411</th>\n",
       "      <td>Anna</td>\n",
       "      <td>Spitzer</td>\n",
       "      <td>,</td>\n",
       "      <td>led</td>\n",
       "      <td>alt</td>\n",
       "      <td>22</td>\n",
       "      <td>J</td>\n",
       "      <td>im</td>\n",
       "      <td>Judensp</td>\n",
       "      <td>in</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7412 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0             1             2         3            4          5   \\\n",
       "0         \\nDem         Peter         Frost     einem       Cammer         im   \n",
       "1           Der         Maria  Nauitschanin     einer      Burgerl     Wittib   \n",
       "2     Christina        Kochin           ein    Wittib           im  Barbieris   \n",
       "3      Gottlieb         Rabel           ein  gewester  Haußmeister       beyn   \n",
       "4      Dominica  Stephanebrin           ein   lediges       Mensch       beym   \n",
       "...         ...           ...           ...       ...          ...        ...   \n",
       "7407    Philipp       Spitzer             ,       led          alt         18   \n",
       "7408         Hr       Bernard          Abbe         v      Berzoni          ,   \n",
       "7409        Der            Fr             .      Cath        Resch          ,   \n",
       "7410         Hr        Daniel        Freyhr   Rottern            v        und   \n",
       "7411       Anna       Spitzer             ,       led          alt         22   \n",
       "\n",
       "                6                7        8            9   ...    56    57  \\\n",
       "0     Greiseckeris             Hauß       im       Diener  ...  None  None   \n",
       "1               im           Primis     Hauß          auf  ...  None  None   \n",
       "2             Hauß              auf      der  Laimgrueben  ...  None  None   \n",
       "3                3           Mohren       in          der  ...  None  None   \n",
       "4          weissen           Ochsen      bey           St  ...  None  None   \n",
       "...            ...              ...      ...          ...  ...   ...   ...   \n",
       "7407             J               im  Judensp           in  ...  None  None   \n",
       "7408             d                h        r            N  ...  None  None   \n",
       "7409            bg  Kaffeehausinhab      Wit            i  ...  None  None   \n",
       "7410            zu       Kostenthal        ,   Weltpriest  ...  None  None   \n",
       "7411             J               im  Judensp           in  ...  None  None   \n",
       "\n",
       "        58    59    60    61    62    63    64    65  \n",
       "0     None  None  None  None  None  None  None  None  \n",
       "1     None  None  None  None  None  None  None  None  \n",
       "2     None  None  None  None  None  None  None  None  \n",
       "3     None  None  None  None  None  None  None  None  \n",
       "4     None  None  None  None  None  None  None  None  \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "7407  None  None  None  None  None  None  None  None  \n",
       "7408  None  None  None  None  None  None  None  None  \n",
       "7409  None  None  None  None  None  None  None  None  \n",
       "7410  None  None  None  None  None  None  None  None  \n",
       "7411  None  None  None  None  None  None  None  None  \n",
       "\n",
       "[7412 rows x 66 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "X Matrix\n",
    "\n",
    "Dimensions # sentences x # sentences (one column samples df, len(sample))\n",
    "\n",
    "'''\n",
    "x_matrix = pd.DataFrame(clean_sterbeliste)\n",
    "\n",
    "print(x_matrix.shape)\n",
    "\n",
    "x_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**T Matrix**\n",
    "\n",
    "np.sparse matirx 1 colum 0, 1 colum 1, rows are keywords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2911, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 1., 1., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "T Matrix\n",
    "Dimensions: # place names x # 2\n",
    "\n",
    "'''\n",
    "a= np.zeros(len(all_loc))\n",
    "b= np.full(len(all_loc),1)\n",
    "\n",
    "t_matrix = np.stack((b,a.T))\n",
    "print(t_matrix.T.shape)\n",
    "\n",
    "t_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Z Matrices**\n",
    "Each sentense is going to be its own Z Matrix.\n",
    "colums = place names\n",
    "rows = words in sentense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 2911)\n",
      "7412\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Z Matrices\n",
    "\n",
    "In the next function, we are building the Z Matrices by looping through all samples.\n",
    "Each sample is compared with the list of locations, if the location is in the sample,\n",
    "the new list \"matched_loc\" gets an entry 1 otherwise a 0 is added\n",
    "Then the list is transformed to an numpy array and brought into shape:\n",
    "\n",
    "Dimensions\n",
    "number of place names x number of words\n",
    "\n",
    "'''\n",
    "locations_list = list(range(0,(len(all_loc.keys()))))\n",
    "\n",
    "## create a list and turn to np.array 3d \n",
    "collected_z_matrices=[]\n",
    "\n",
    "for sample in samples:\n",
    "    matched_loc= [1 if i == j else 0 for i in sample for j in locations_list]\n",
    "    i=len(sample)\n",
    "    Z = np.array(matched_loc)\n",
    "    Z = np.reshape(Z, (i,len(locations_list)))\n",
    "    collected_z_matrices.append(Z)\n",
    "\n",
    "print(Z.shape)\n",
    "\n",
    "\n",
    "print(len(collected_z_matrices))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 2911)\n"
     ]
    }
   ],
   "source": [
    "print(collected_z_matrices[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spilt the test and training z_matrices\n",
    "test_rule_matches_sparse_z_list = collected_z_matrices[:100]\n",
    "\n",
    "train_rule_matches_sparse_z_list = collected_z_matrices[100:]\n",
    "\n",
    "# These lists can't be stacked to a tensor yet, as they need padding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../../data_from_minio/wiener_diarum_toponyms/mapping_rules_labels_t.lib']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# saving the z_matrices\n",
    "\n",
    "\n",
    "dump(train_rule_matches_sparse_z_list, os.path.join(data_path, \"train_rule_matches_z_list.lib\"))\n",
    "dump(test_rule_matches_sparse_z_list, os.path.join(data_path, \"test_rule_matches_z_list.lib\"))\n",
    "\n",
    "\n",
    "# saving the t_matix\n",
    "\n",
    "dump(t_matrix,  os.path.join(data_path, \"mapping_rules_labels_t.lib\").replace('\\\\','/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Building test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The provided test data has information about the character position of each place name. \n",
    "The data also considers tags, special characters and other non-verbal characters.\n",
    "For our use, this test data can not be used as we want to train our model to look for place names within a sentence and not on a character level.\n",
    "We might need to take a part of our training data, manually check each sentence and its tagging and use it as our test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building test data, the first 100 samples have been manually checked\n",
    "\n",
    "df_test = df[:100]\n",
    "\n",
    "# Saving them\n",
    "\n",
    "df_test.to_csv(os.path.join(data_path, 'df_test.csv'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Overview \n",
    "\n",
    "In this tutorial we have created a data set that is suitable to train a sequence labeler as well as the matrices needed for the Knodle framework. \n",
    "\n",
    "We have dealt with messy data that contains unnormalised historical language. \n",
    "\n",
    "We started with the .html file (=\"l\" containing the obituaries and end with a df_train containing samples and their labeling, a df_test containing 100 manually checked labels.\n",
    "And three lib files containing the t_matrix ( # toponoym/not toponym x # number of all pace names aka. rules) the z-matirces collected as a list one z_matrix being #words in sentence x # all place names aka. rules) both for the test samples (test_rule_matches_z_list) and the train samples (train_rule_matches_z_list)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['df_test.csv',\n",
       " 'df_train.csv',\n",
       " 'l',\n",
       " 'mapping_rules_labels_t.lib',\n",
       " 'test_rule_matches_z_list.lib',\n",
       " 'train_rule_matches_z_list.lib']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(data_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
